{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrYrQR8cLOMqHd/HNRRsEQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkumar61/MAT421/blob/main/Module_I_Section_2_2%2C_2_3%2C_2_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Probability and Random Variables\n",
        "\n",
        "## Basic Definitions\n",
        "\n",
        "### Probability\n",
        "\n",
        "Probability measures the likelihood of an event occurring. It's often represented as a number between 0 and 1, where 0 indicates impossibility and 1 indicates certainty.\n",
        "\n",
        "### Random Experiment\n",
        "\n",
        "A random experiment is an experiment whose outcome is uncertain. Examples include flipping a coin, rolling a die, or selecting a card from a deck.\n",
        "\n",
        "### Sample Space\n",
        "\n",
        "The sample space ($ S $) of a random experiment is the set of all possible outcomes.\n",
        "\n",
        "### Event\n",
        "\n",
        "An event ($ E $) is a subset of the sample space, representing a particular outcome or a combination of outcomes.\n",
        "\n",
        "## Random Variables\n",
        "\n",
        "A random variable is a variable that can take on different values as a result of a random experiment. It can be classified into two types: discrete and continuous.\n",
        "\n",
        "### Discrete Random Variable\n",
        "\n",
        "A discrete random variable is one that takes on a countable number of distinct values.\n",
        "\n",
        "### Continuous Random Variable\n",
        "\n",
        "A continuous random variable is one that can take on any value within a given range.\n",
        "\n",
        "## Expectation and Variance\n",
        "\n",
        "### Expectation\n",
        "\n",
        "The expectation (or expected value) of a random variable is the average value it would take over an infinite number of repetitions of the experiment.\n",
        "\n",
        "#### Discrete Random Variable\n",
        "\n",
        "For a discrete random variable $ X $, the expectation ($ E[X] $) is calculated as:\n",
        "\n",
        "$$ E[X] = \\sum_{x} x P(X = x) $$\n",
        "\n",
        "Where $ x $ ranges over all possible values of $ X $, and $ P(X = x) $ is the probability mass function.\n",
        "\n",
        "#### Continuous Random Variable\n",
        "\n",
        "For a continuous random variable $ Y $ with probability density function $ f(y) $, the expectation ($ E[Y] $) is calculated as:\n",
        "\n",
        "$$ E[Y] = \\int_{-\\infty}^{\\infty} y f(y) \\, dy $$\n",
        "\n",
        "### Variance\n",
        "\n",
        "The variance of a random variable measures how much its values vary around the mean.\n",
        "\n",
        "#### Discrete Random Variable\n",
        "\n",
        "For a discrete random variable $ X $, the variance ($ \\text{Var}(X) $) is calculated as:\n",
        "\n",
        "$$ \\text{Var}(X) = E[(X - E[X])^2] = \\sum_{x} (x - E[X])^2 P(X = x) $$\n",
        "\n",
        "#### Continuous Random Variable\n",
        "\n",
        "For a continuous random variable $ Y $ with probability density function $ f(y) $, the variance ($ \\text{Var}(Y) $) is calculated as:\n",
        "\n",
        "$$ \\text{Var}(Y) = E[(Y - E[Y])^2] = \\int_{-\\infty}^{\\infty} (y - E[Y])^2 f(y) \\, dy $$\n"
      ],
      "metadata": {
        "id": "qGNxnZ9uOOds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTS6EDnoOMuU",
        "outputId": "23532e0a-9e92-4048-d0b0-a02c269d6285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expectation (Discrete): 3.5\n",
            "Variance (Discrete): 2.9166666666666665\n",
            "Expectation (Continuous): 5.485150682021838\n",
            "Variance (Continuous): 0.24289704539927112\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example: Calculating expectation and variance for a discrete random variable\n",
        "\n",
        "def pmf(x):\n",
        "    return 1/6  # Assuming a fair six-sided die\n",
        "\n",
        "def expectation_discrete(pmf):\n",
        "    return sum(x * pmf(x) for x in range(1, 7))\n",
        "def variance_discrete(pmf):\n",
        "    exp_x = expectation_discrete(pmf)\n",
        "    return sum((x - exp_x) ** 2 * pmf(x) for x in range(1, 7))\n",
        "\n",
        "exp_value_discrete = expectation_discrete(pmf)\n",
        "var_value_discrete = variance_discrete(pmf)\n",
        "print(\"Expectation (Discrete):\", exp_value_discrete)\n",
        "print(\"Variance (Discrete):\", var_value_discrete)\n",
        "\n",
        "# Example: Calculating expectation and variance for a continuous random variable\n",
        "def pdf(y, mean, std_dev):\n",
        "    return 1 / (std_dev * np.sqrt(2 * np.pi)) * np.exp(-(y - mean)**2 / (2 * std_dev**2)) # Assuming Normal distribution\n",
        "\n",
        "def expectation_continuous(pdf, mean, std_dev):\n",
        "    return np.trapz(y * pdf(y, mean, std_dev), y)\n",
        "\n",
        "def variance_continuous(pdf, mean, std_dev):\n",
        "    exp_y = expectation_continuous(pdf, mean, std_dev)\n",
        "    return np.trapz((y - exp_y)**2 * pdf(y, mean, std_dev), y)\n",
        "\n",
        "y = np.linspace(4, 7, 1000)\n",
        "mean_height = 5.5\n",
        "std_dev_height = 0.5\n",
        "\n",
        "exp_value_continuous = expectation_continuous(pdf, mean_height, std_dev_height)\n",
        "var_value_continuous = variance_continuous(pdf, mean_height, std_dev_height)\n",
        "print(\"Expectation (Continuous):\", exp_value_continuous)\n",
        "print(\"Variance (Continuous):\", var_value_continuous)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Joint Random Variables, Independence, and Random Samples\n",
        "\n",
        "## Joint Random Variables\n",
        "\n",
        "When dealing with multiple random variables simultaneously, we often consider their joint behavior.\n",
        "\n",
        "### Joint Probability Mass Function (PMF)\n",
        "\n",
        "For discrete random variables $ X $ and $ Y $, the joint probability mass function $ P(X=x, Y=y) $ gives the probability that $ X=x $ and $ Y=y $ simultaneously.\n",
        "\n",
        "### Joint Probability Density Function (PDF)\n",
        "\n",
        "For continuous random variables $ X $ and $ Y $, the joint probability density function $ f(x, y) $ gives the probability density at the point $ (x, y) $.\n",
        "\n",
        "## Independence\n",
        "\n",
        "Two random variables $ X $ and $ Y $ are independent if knowing the value of one provides no information about the value of the other.\n",
        "\n",
        "### Discrete Random Variables\n",
        "\n",
        "For discrete random variables, independence is defined by the product of their individual probability mass functions: $ P(X=x, Y=y) = P(X=x) \\times P(Y=y) $ for all $ x $ and $ y $.\n",
        "\n",
        "### Continuous Random Variables\n",
        "\n",
        "For continuous random variables, independence is defined by the product of their individual probability density functions: $ f(x, y) = f_X(x) \\times f_Y(y) $ for all $ x $ and $ y $.\n",
        "\n",
        "## Random Samples\n",
        "\n",
        "Random samples are collections of random variables drawn from the same distribution.\n",
        "\n",
        "### Sample Mean\n",
        "\n",
        "The sample mean ($ \\bar{X} $) of a random sample $ X_1, X_2, ..., X_n $ is the average of the observations: $ \\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i $.\n",
        "\n",
        "### Sample Variance\n",
        "\n",
        "The sample variance ($ S^2 $) of a random sample $ X_1, X_2, ..., X_n $ measures how much the observations deviate from the sample mean: $ S^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})^2 $.\n",
        "\n",
        "### Central Limit Theorem\n",
        "\n",
        "The Central Limit Theorem states that the distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the distribution of the individual observations.\n",
        "\n"
      ],
      "metadata": {
        "id": "RqWM-aK2P2cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a random sample (e.g., from a normal distribution)\n",
        "sample_size = 1000\n",
        "random_sample = np.random.normal(loc=0, scale=1, size=sample_size)\n",
        "\n",
        "# Calculate sample mean\n",
        "sample_mean = np.mean(random_sample)\n",
        "\n",
        "# Calculate sample variance\n",
        "sample_variance = np.var(random_sample, ddof=1)\n",
        "\n",
        "# Print results\n",
        "print(\"Sample Mean:\", sample_mean)\n",
        "print(\"Sample Variance:\", sample_variance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35N6sntfPJ-x",
        "outputId": "da74d087-8cd9-4076-ba7b-599af6ddfc8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Mean: -0.010518088224090545\n",
            "Sample Variance: 0.9822458815860513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Likelihood Function\n",
        "\n",
        "In MLE, we start by defining a likelihood function, denoted by $ L(\\theta | \\mathbf{x}) $, where $ \\theta $ represents the parameters of the model and $ \\mathbf{x} $ represents the observed data. The likelihood function measures how likely the observed data is for different values of the parameters.\n",
        "\n",
        "### Maximizing Likelihood\n",
        "\n",
        "The goal of MLE is to find the values of the parameters $ \\theta $ that maximize the likelihood function. Mathematically, this can be expressed as:\n",
        "\n",
        "$$ \\hat{\\theta}_{\\text{MLE}} = \\arg \\max_{\\theta} L(\\theta | \\mathbf{x}) $$\n",
        "\n",
        "Where $ \\hat{\\theta}_{\\text{MLE}} $ represents the estimated parameter values that maximize the likelihood.\n",
        "\n",
        "### Log-Likelihood Function\n",
        "\n",
        "To simplify calculations and avoid numerical underflow, we often work with the log-likelihood function, denoted by $ \\ell(\\theta | \\mathbf{x}) $, which is the natural logarithm of the likelihood function:\n",
        "\n",
        "$$ \\ell(\\theta | \\mathbf{x}) = \\log L(\\theta | \\mathbf{x}) $$\n",
        "\n",
        "The log-likelihood function has the same maximum as the likelihood function but is easier to work with, especially for complex models or large datasets.\n",
        "\n",
        "### Properties\n",
        "\n",
        "MLE possesses some desirable properties, such as consistency, efficiency, and asymptotic normality. Consistency means that as the sample size increases, the estimates converge to the true parameter values. Efficiency refers to the fact that MLE provides the most efficient estimates among all unbiased estimators. Asymptotic normality means that for large sample sizes, the distribution of the MLE estimates approaches a normal distribution centered around the true parameter values."
      ],
      "metadata": {
        "id": "50Ktqm8NQFM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.random.normal(loc=2.0, scale=1.5, size=1000)\n",
        "\n",
        "# Calculate the MLE estimates for mean and variance\n",
        "n = len(data)\n",
        "mu_mle = np.sum(data) / n  # MLE estimate for the mean\n",
        "sigma_mle = np.sqrt(np.sum((data - mu_mle)**2) / n)  # MLE estimate for the standard deviation\n",
        "\n",
        "# Print the results\n",
        "print(\"MLE Estimated Mean:\", mu_mle)\n",
        "print(\"MLE Estimated Standard Deviation:\", sigma_mle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBi_ReetQEa_",
        "outputId": "ea884abf-36b1-48f8-b438-9f8e6be5fc5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLE Estimated Mean: 1.9507454066402696\n",
            "MLE Estimated Standard Deviation: 1.5267055294633878\n"
          ]
        }
      ]
    }
  ]
}